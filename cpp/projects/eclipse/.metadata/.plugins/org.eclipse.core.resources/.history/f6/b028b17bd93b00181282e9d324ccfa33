/*
 * ClassCamCalib.cpp
 *
 *  Created on: Apr 9, 2018
 *      Author: mauricio
 */

#include "ClassCamCalib.h"

using json = nlohmann::json;

ClassCamCalib::ClassCamCalib() {
	// TODO Auto-generated constructor stub

}

ClassCamCalib::~ClassCamCalib() {
	// TODO Auto-generated destructor stub
}


cv::Point2f ClassCamCalib::Project3DTo2D(cv::Point3f point, cv::Mat cameraMatrix, cv::Mat rvec, cv::Mat tvec, cv::Mat distorsion) {
	cv::Mat cameraRotation;
	Rodrigues(rvec, cameraRotation);

	cv::Mat pointMat(4, 1, CV_64F);
	pointMat.at<double>(0, 0) = point.x;
	pointMat.at<double>(1, 0) = point.y;
	pointMat.at<double>(2, 0) = point.z;
	pointMat.at<double>(3, 0) = 1;

	cv::Mat PMatrix(3, 4, cameraRotation.type()); // T is 3x4
	PMatrix(cv::Range(0,3), cv::Range(0,3)) = cameraRotation * 1; // copies R into T
	PMatrix(cv::Range(0,3), cv::Range(3,4)) = tvec * 1; // copies tvec into T

	cv::Mat resultPoint = cameraMatrix * PMatrix * pointMat;

	auto xValue = resultPoint.at<double>(0) / resultPoint.at<double>(2);
	auto yValue = resultPoint.at<double>(1) / resultPoint.at<double>(2);
	std::cout << "x" << xValue << std::endl;
	std::cout << "y" << yValue << std::endl;

	return cv::Point2f(xValue, yValue);
}

cv::Point3f ClassCamCalib::Project2DTo3D(cv::Point2f point, cv::Mat cameraMatrix, cv::Mat rvec, cv::Mat tvec, cv::Mat distorsion) {
	// Stack overflow references
	// https://stackoverflow.com/questions/48038817/opencv-get-3d-coordinates-from-2d-pixel

	// Como realizar el despeje de las ecuaciones
	// https://stackoverflow.com/questions/12299870/computing-x-y-coordinate-3d-from-image-point

	// Obtencion de parametros intrinsecos de la camara
	// http://answers.opencv.org/question/17076/conversion-focal-distance-from-mm-to-pixels/

	cv::Mat cameraRotation;
	Rodrigues(rvec, cameraRotation);

	cv::Mat pointMat(3, 1, CV_64F);
	pointMat.at<double>(0, 0) = point.x;
	pointMat.at<double>(1, 0) = point.y;
	pointMat.at<double>(2, 0) = 1;

	cv::Mat PMatrix(3, 3, cameraRotation.type()); // T is 3x4
	setIdentity(PMatrix);

	PMatrix(cv::Range(0,3), cv::Range(0, 2)) = cameraRotation(cv::Range(0,3), cv::Range(0,2)) * 1;

	PMatrix.at<double>(0, 2) = tvec.at<double>(0, 0);
	PMatrix.at<double>(1, 2) = tvec.at<double>(1, 0);
	PMatrix.at<double>(2, 2) = tvec.at<double>(2, 0);

	cv::Mat pointResult = PMatrix.inv() * cameraMatrix.inv() * pointMat;

	auto xValue = pointResult.at<double>(0) / pointResult.at<double>(2);
	auto yValue = pointResult.at<double>(1) / pointResult.at<double>(2);
	std::cout << "x" << xValue << std::endl;
	std::cout << "y" << yValue << std::endl;

	return cv::Point3f(xValue, yValue, 0);
}

CalibResults ClassCamCalib::CalibrateCamera(std::vector<cv::Point2f> listPoints2D, std::vector<cv::Point3f> listPoints3D) {
	CalibResults results;

	// Assuming ideal camera Matrix
	// No need to get intrinsic coefficients
	results.cameraMatrix = cv::Mat(3, 3, cv::DataType<double>::type);
	results.cameraMatrix.at<double>(0,0) = 908.65;
	results.cameraMatrix.at<double>(0,1) = 0;
	results.cameraMatrix.at<double>(0,2) = 642;

	results.cameraMatrix.at<double>(1,0) = 0;
	results.cameraMatrix.at<double>(1,1) = 909;
	results.cameraMatrix.at<double>(1,2) = 364;

	results.cameraMatrix.at<double>(2,0) = 0;
	results.cameraMatrix.at<double>(2,1) = 0;
	results.cameraMatrix.at<double>(2,2) = 1;

	results.distortion = Mat(4,1,cv::DataType<double>::type);
	results.distortion.at<double>(0) = 0;
	results.distortion.at<double>(1) = 0;
	results.distortion.at<double>(2) = 0;
	results.distortion.at<double>(3) = 0;

	results.rvec = cv::Mat(3,1,cv::DataType<double>::type);
	results.tvec = cv::Mat(3,1,cv::DataType<double>::type);

	cv::solvePnP(listPoints3D, listPoints2D, results.cameraMatrix, results.distortion, results.rvec, results.tvec);
	return results;
}


std::string CalibResultsToString(CalibResults results) {
	json obj;

	obj["cameraMatrix"] ImageProcess::GetCSV(results.cameraMatrix);
	obj["distortion"] = ImageProcess::GetCSV(results.distortion);
	obj["rvec"] = ImageProcess::GetCSV(results.rvec);
	obj["rvec"] = ImageProcess::GetCSV(results.rvec);
}

