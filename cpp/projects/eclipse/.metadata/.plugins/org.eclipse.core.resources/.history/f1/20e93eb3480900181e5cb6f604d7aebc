/*
 * ClassOpenPose.cpp
 *
 *  Created on: Feb 3, 2018
 *      Author: mauricio
 */

#include "ClassOpenPose.h"


ClassOpenPose::ClassOpenPose() {
	// TODO Auto-generated constructor stub
}

ClassOpenPose::~ClassOpenPose() {
	// TODO Auto-generated destructor stub
}

void ClassOpenPose::InitOpenPose() {
	op::log("Initializing open pose");

	// Step 1 - Set logging level
	// - 0 will output all the logging messages
	// - 255 will output nothing
	op::check(0 <= logging_level && logging_level <= 255, "Wrong logging_level value.", __LINE__, __FUNCTION__, __FILE__);
	op::ConfigureLog::setPriorityThreshold((op::Priority)logging_level);
	op::log("", op::Priority::Low, __LINE__, __FUNCTION__, __FILE__);

	// Step 2 - Read Google flags (user defined configuration)
	// outputSize
	const auto outputSize = op::flagsToPoint(output_resolution, "-1x-1");
	// netInputSize
	const auto netInputSize = op::flagsToPoint(net_resolution, "-1x368");
	// poseModel
	const auto poseModel = op::flagsToPoseModel(model_pose);

	// Check no contradictory flags enabled
	if (alpha_pose < 0. || alpha_pose > 1.)
		op::error("Alpha value for blending must be in the range [0,1].",
				  __LINE__, __FUNCTION__, __FILE__);

	if (scale_gap <= 0. && scale_number > 1)
		op::error("Incompatible flag configuration: scale_gap must be greater than 0 or scale_number = 1.",
				  __LINE__, __FUNCTION__, __FILE__);

	// Logging
	op::log("", op::Priority::Low, __LINE__, __FUNCTION__, __FILE__);

	// Step 3 - Initialize all required classes
	scaleAndSizeExtractor = op::ScaleAndSizeExtractor(netInputSize, outputSize, scale_number, scale_gap);
	poseExtractorCaffe = op::PoseExtractorCaffe({poseModel, model_folder, num_gpu_start});

    poseRenderer = 	op::PoseCpuRenderer{poseModel, (float)render_threshold, !disable_blending, (float)alpha_pose};
	frameDisplayer = op::FrameDisplayer({"OpenPose Tutorial - Example 1", outputSize});

	// Step 4 - Initialize resources on desired thread (in this case single thread, i.e. we init resources here)
	poseExtractorCaffe.initializationOnThread();
	poseRenderer.initializationOnThread();
}

void ClassOpenPose::ExtractKeyPoints(cv::Mat image) {
	op::log("Extracting image");
}

void ClassOpenPose::ExtractAndShow(cv::Mat inputImage) {
	//Step 1 already tested - Image loaded
	op::log("Extract and show image");

	const op::Point<int> imageSize{inputImage.cols, inputImage.rows};

	// Step 2 - Get desired scale sizes
	std::vector<double> scaleInputToNetInputs;
	std::vector<op::Point<int>> netInputSizes;
	double scaleInputToOutput;
	op::Point<int> outputResolution;

	std::tie(scaleInputToNetInputs, netInputSizes, scaleInputToOutput, outputResolution)
		= scaleAndSizeExtractor.extract(imageSize);

	// Step 3 - Format input image to OpenPose input and output formats
	const auto netInputArray = cvMatToOpInput.createArray(inputImage, scaleInputToNetInputs, netInputSizes);
	auto outputArray = cvMatToOpOutput.createArray(inputImage, scaleInputToOutput, outputResolution);

	// Step 4 - Estimate poseKeypoints
	poseExtractorCaffe.forwardPass(netInputArray, imageSize, scaleInputToNetInputs);
	const auto poseKeypoints = poseExtractorCaffe.getPoseKeypoints();
	const auto poseScores = poseExtractorCaffe.getPoseScores();


	//Extracting poses
	auto sizeElems = poseKeypoints.getSize();

	if (poseKeypoints.empty() == false) {

		for (auto person = 0; person < poseKeypoints.getSize(0); person++) {
			std::cout << "person: " << person << std::endl;

			for (auto bodyPart = 0 ; bodyPart < poseKeypoints.getSize(1) ; bodyPart++) {
				std::string valueToPrint;
				for (auto xyscore = 0 ; xyscore < poseKeypoints.getSize(2) ; xyscore++) {
					valueToPrint += std::to_string(poseKeypoints[{person, bodyPart, xyscore}]) + " ";
				}
				op::log(valueToPrint);
			}
		}
	}

	for (uint i = 0; i < sizeElems.size(); i++) {
		std::cout << "Size element: " << i << " : " << sizeElems[i] << std::endl;
	}

	//Extracting pose scores
	auto sizeScore = poseScores.getSize();

	for (uint i = 0; i < sizeScore.size(); i++) {
		std::cout << "Size score: " << i << " : " << sizeScore[i] << std::endl;
	}


	const cv::Mat cvMat = poseKeypoints.getConstCvMat();
	cv::imwrite("/home/mauricio/file.jpg", cvMat);

	// Step 5 - Render poseKey points
	poseRenderer.renderPose(outputArray, poseKeypoints, scaleInputToOutput);

	// Step 6 - OpenPose output format to cv::Mat
	auto outputImage = opOutputToCvMat.formatToCvMat(outputArray);

	// ------------------------- SHOWING RESULT AND CLOSING -------------------------
	// Step 1 - Show results
	frameDisplayer.displayFrame(outputImage, 0); // Alternative: cv::imshow(outputImage) + cv::waitKey(0)
	// Step 2 - Logging information message
	op::log("Example 1 successfully finished.", op::Priority::High);

}




